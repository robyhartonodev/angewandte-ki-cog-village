{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Import libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np \r\n",
    "import pickle\r\n",
    "import os\r\n",
    "\r\n",
    "from itertools import cycle\r\n",
    "from collections import defaultdict\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\r\n",
    "from sklearn.feature_selection import SelectFromModel\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, label_binarize\r\n",
    "from sklearn.metrics import roc_curve, auc\r\n",
    "from sklearn.multiclass import OneVsRestClassifier\r\n",
    "\r\n",
    "from helper import plot_classifier\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Load data, extract data and label"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "rootdir = os.getcwd() + \"/data/training/\"\r\n",
    "\r\n",
    "data             = []\r\n",
    "data_label       = []\r\n",
    "\r\n",
    "\r\n",
    "for subdir, dirs, files in os.walk(rootdir):\r\n",
    "    for fl in files:\r\n",
    "        if fl.endswith('.pkl'):\r\n",
    "            # string split for event labelling\r\n",
    "            str_arr = fl.split('_')\r\n",
    "            label   = str_arr[1]\r\n",
    "\r\n",
    "            # read data and append it to variable\r\n",
    "            infile = open((rootdir + fl),'rb')\r\n",
    "            new_dict = pickle.load(infile, encoding='latin1')\r\n",
    "\r\n",
    "            data.append(new_dict)\r\n",
    "            data_label.append(new_dict['label'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Feature Generation - Mean, Variance, Maximum and Minimum"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "keys = [\r\n",
    "    'Magnetometer', \r\n",
    "    'Accelerometer', \r\n",
    "    'LinearAccelerometer', \r\n",
    "    'JinsGyroscope', \r\n",
    "    'Gravity', \r\n",
    "    'MSAccelerometer',\r\n",
    "    'JinsAccelerometer',\r\n",
    "    'MSGyroscope',\r\n",
    "    'Gyroscope',\r\n",
    "    'JinsEyeMovement',\r\n",
    "    # 'JinsBlinkStrength', Excluded because some data has no JinsBlinkStrength data\r\n",
    "    'rightHand',\r\n",
    "    'label'\r\n",
    "]\r\n",
    "\r\n",
    "ary = []\r\n",
    "for dt in data:\r\n",
    "    internal = []\r\n",
    "    for key in keys[:-2]:\r\n",
    "        feature = dt[key]\r\n",
    "        # print(f\"Shape von Feature {key}: {feature.shape}\")\r\n",
    "        for column in feature.T:\r\n",
    "            internal.append(np.mean(column))\r\n",
    "            internal.append(np.var(column))\r\n",
    "            internal.append(np.max(column))\r\n",
    "            internal.append(np.min(column))\r\n",
    "            \r\n",
    "    # Right hand - If true 1 else 0\r\n",
    "    right_hand = 1 if dt[\"rightHand\"] else 0\r\n",
    "    internal.append(right_hand)\r\n",
    "\r\n",
    "    internal.append(dt[\"label\"])\r\n",
    "\r\n",
    "    ary.append(internal)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Added columns name to the data frame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df = pd.DataFrame(ary)\r\n",
    "\r\n",
    "# Name df columns, so it's more clear\r\n",
    "df_columns = []\r\n",
    "\r\n",
    "# Iterate through except label, rightHand, JinsEyeMovement, JinsBlinkStrength\r\n",
    "for key in keys[:-3]:\r\n",
    "    df_columns.append('{} X (mean)'.format(key))\r\n",
    "    df_columns.append('{} X (var)'.format(key))\r\n",
    "    df_columns.append('{} X (max)'.format(key))\r\n",
    "    df_columns.append('{} X (min)'.format(key))\r\n",
    "\r\n",
    "    df_columns.append('{} Y (mean)'.format(key))\r\n",
    "    df_columns.append('{} Y (var)'.format(key))\r\n",
    "    df_columns.append('{} Y (max)'.format(key))\r\n",
    "    df_columns.append('{} Y (min)'.format(key))\r\n",
    "\r\n",
    "    df_columns.append('{} Z (mean)'.format(key))\r\n",
    "    df_columns.append('{} Z (var)'.format(key))\r\n",
    "    df_columns.append('{} Z (max)'.format(key))\r\n",
    "    df_columns.append('{} Z (min)'.format(key))\r\n",
    "\r\n",
    "# JinsEyeMovement (4 dimensions)\r\n",
    "for i in range(4):\r\n",
    "    df_columns.append('JinsEyeMovement Dim-{} (mean)'.format(i+1))\r\n",
    "    df_columns.append('JinsEyeMovement Dim-{} (var)'.format(i+1))\r\n",
    "    df_columns.append('JinsEyeMovement Dim-{} (max)'.format(i+1))\r\n",
    "    df_columns.append('JinsEyeMovement Dim-{} (min)'.format(i+1))\r\n",
    "\r\n",
    "df_columns.append('rightHand')\r\n",
    "\r\n",
    "df_columns.append('label')\r\n",
    "\r\n",
    "df.columns = df_columns\r\n",
    "\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Magnetometer X (mean)</th>\n",
       "      <th>Magnetometer X (var)</th>\n",
       "      <th>Magnetometer X (max)</th>\n",
       "      <th>Magnetometer X (min)</th>\n",
       "      <th>Magnetometer Y (mean)</th>\n",
       "      <th>Magnetometer Y (var)</th>\n",
       "      <th>Magnetometer Y (max)</th>\n",
       "      <th>Magnetometer Y (min)</th>\n",
       "      <th>Magnetometer Z (mean)</th>\n",
       "      <th>Magnetometer Z (var)</th>\n",
       "      <th>...</th>\n",
       "      <th>JinsEyeMovement Dim-3 (mean)</th>\n",
       "      <th>JinsEyeMovement Dim-3 (var)</th>\n",
       "      <th>JinsEyeMovement Dim-3 (max)</th>\n",
       "      <th>JinsEyeMovement Dim-3 (min)</th>\n",
       "      <th>JinsEyeMovement Dim-4 (mean)</th>\n",
       "      <th>JinsEyeMovement Dim-4 (var)</th>\n",
       "      <th>JinsEyeMovement Dim-4 (max)</th>\n",
       "      <th>JinsEyeMovement Dim-4 (min)</th>\n",
       "      <th>rightHand</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.991582</td>\n",
       "      <td>3.368823</td>\n",
       "      <td>9.3125</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>-32.884439</td>\n",
       "      <td>0.634716</td>\n",
       "      <td>-31.1875</td>\n",
       "      <td>-35.2500</td>\n",
       "      <td>26.872449</td>\n",
       "      <td>0.663769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.999238</td>\n",
       "      <td>7.892133</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>-2.5625</td>\n",
       "      <td>-40.103659</td>\n",
       "      <td>1.256309</td>\n",
       "      <td>-37.8750</td>\n",
       "      <td>-43.4375</td>\n",
       "      <td>-1.536331</td>\n",
       "      <td>3.767433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.244621</td>\n",
       "      <td>33.212013</td>\n",
       "      <td>14.1250</td>\n",
       "      <td>-1.7500</td>\n",
       "      <td>-37.640113</td>\n",
       "      <td>1.081339</td>\n",
       "      <td>-35.2500</td>\n",
       "      <td>-40.8125</td>\n",
       "      <td>9.581711</td>\n",
       "      <td>26.765016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.289634</td>\n",
       "      <td>0.321695</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>6.6875</td>\n",
       "      <td>-39.676829</td>\n",
       "      <td>0.765797</td>\n",
       "      <td>-37.8750</td>\n",
       "      <td>-41.9375</td>\n",
       "      <td>3.122967</td>\n",
       "      <td>1.000790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.582317</td>\n",
       "      <td>0.217309</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>17.3750</td>\n",
       "      <td>-39.456047</td>\n",
       "      <td>0.764281</td>\n",
       "      <td>-37.5000</td>\n",
       "      <td>-41.5625</td>\n",
       "      <td>-7.030488</td>\n",
       "      <td>0.467312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>57.716972</td>\n",
       "      <td>143.881277</td>\n",
       "      <td>70.9375</td>\n",
       "      <td>23.0625</td>\n",
       "      <td>-8.623476</td>\n",
       "      <td>6.323994</td>\n",
       "      <td>-1.8125</td>\n",
       "      <td>-14.3125</td>\n",
       "      <td>54.860010</td>\n",
       "      <td>121.039457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>60.309959</td>\n",
       "      <td>32.958549</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>45.8750</td>\n",
       "      <td>-9.146341</td>\n",
       "      <td>3.963309</td>\n",
       "      <td>-3.6875</td>\n",
       "      <td>-13.9375</td>\n",
       "      <td>52.580285</td>\n",
       "      <td>101.322569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>62.244157</td>\n",
       "      <td>22.920205</td>\n",
       "      <td>70.1875</td>\n",
       "      <td>49.9375</td>\n",
       "      <td>-10.478659</td>\n",
       "      <td>6.692094</td>\n",
       "      <td>-4.0625</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>52.757876</td>\n",
       "      <td>97.716036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>62.617378</td>\n",
       "      <td>22.964754</td>\n",
       "      <td>72.7500</td>\n",
       "      <td>52.1250</td>\n",
       "      <td>-9.737551</td>\n",
       "      <td>7.747225</td>\n",
       "      <td>-3.3125</td>\n",
       "      <td>-16.5625</td>\n",
       "      <td>51.687246</td>\n",
       "      <td>73.808673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>61.275661</td>\n",
       "      <td>55.696099</td>\n",
       "      <td>74.1875</td>\n",
       "      <td>44.3750</td>\n",
       "      <td>-9.474085</td>\n",
       "      <td>5.773338</td>\n",
       "      <td>-3.3125</td>\n",
       "      <td>-15.4375</td>\n",
       "      <td>49.036585</td>\n",
       "      <td>89.215951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows Ã— 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Magnetometer X (mean)  Magnetometer X (var)  Magnetometer X (max)  \\\n",
       "0                 4.991582              3.368823                9.3125   \n",
       "1                 4.999238              7.892133                7.7500   \n",
       "2                 8.244621             33.212013               14.1250   \n",
       "3                 8.289634              0.321695                9.6875   \n",
       "4                18.582317              0.217309               20.0000   \n",
       "..                     ...                   ...                   ...   \n",
       "254              57.716972            143.881277               70.9375   \n",
       "255              60.309959             32.958549               72.0000   \n",
       "256              62.244157             22.920205               70.1875   \n",
       "257              62.617378             22.964754               72.7500   \n",
       "258              61.275661             55.696099               74.1875   \n",
       "\n",
       "     Magnetometer X (min)  Magnetometer Y (mean)  Magnetometer Y (var)  \\\n",
       "0                  1.9375             -32.884439              0.634716   \n",
       "1                 -2.5625             -40.103659              1.256309   \n",
       "2                 -1.7500             -37.640113              1.081339   \n",
       "3                  6.6875             -39.676829              0.765797   \n",
       "4                 17.3750             -39.456047              0.764281   \n",
       "..                    ...                    ...                   ...   \n",
       "254               23.0625              -8.623476              6.323994   \n",
       "255               45.8750              -9.146341              3.963309   \n",
       "256               49.9375             -10.478659              6.692094   \n",
       "257               52.1250              -9.737551              7.747225   \n",
       "258               44.3750              -9.474085              5.773338   \n",
       "\n",
       "     Magnetometer Y (max)  Magnetometer Y (min)  Magnetometer Z (mean)  \\\n",
       "0                -31.1875              -35.2500              26.872449   \n",
       "1                -37.8750              -43.4375              -1.536331   \n",
       "2                -35.2500              -40.8125               9.581711   \n",
       "3                -37.8750              -41.9375               3.122967   \n",
       "4                -37.5000              -41.5625              -7.030488   \n",
       "..                    ...                   ...                    ...   \n",
       "254               -1.8125              -14.3125              54.860010   \n",
       "255               -3.6875              -13.9375              52.580285   \n",
       "256               -4.0625              -15.4375              52.757876   \n",
       "257               -3.3125              -16.5625              51.687246   \n",
       "258               -3.3125              -15.4375              49.036585   \n",
       "\n",
       "     Magnetometer Z (var)  ...  JinsEyeMovement Dim-3 (mean)  \\\n",
       "0                0.663769  ...                           0.0   \n",
       "1                3.767433  ...                           0.0   \n",
       "2               26.765016  ...                           0.0   \n",
       "3                1.000790  ...                           0.0   \n",
       "4                0.467312  ...                           0.0   \n",
       "..                    ...  ...                           ...   \n",
       "254            121.039457  ...                           0.0   \n",
       "255            101.322569  ...                           0.0   \n",
       "256             97.716036  ...                           0.0   \n",
       "257             73.808673  ...                           0.0   \n",
       "258             89.215951  ...                           0.0   \n",
       "\n",
       "     JinsEyeMovement Dim-3 (var)  JinsEyeMovement Dim-3 (max)  \\\n",
       "0                            0.0                          0.0   \n",
       "1                            0.0                          0.0   \n",
       "2                            0.0                          0.0   \n",
       "3                            0.0                          0.0   \n",
       "4                            0.0                          0.0   \n",
       "..                           ...                          ...   \n",
       "254                          0.0                          0.0   \n",
       "255                          0.0                          0.0   \n",
       "256                          0.0                          0.0   \n",
       "257                          0.0                          0.0   \n",
       "258                          0.0                          0.0   \n",
       "\n",
       "     JinsEyeMovement Dim-3 (min)  JinsEyeMovement Dim-4 (mean)  \\\n",
       "0                            0.0                      0.009901   \n",
       "1                            0.0                      0.000000   \n",
       "2                            0.0                      0.000000   \n",
       "3                            0.0                      0.010000   \n",
       "4                            0.0                      0.000000   \n",
       "..                           ...                           ...   \n",
       "254                          0.0                      0.000000   \n",
       "255                          0.0                      0.000000   \n",
       "256                          0.0                      0.010000   \n",
       "257                          0.0                      0.000000   \n",
       "258                          0.0                      0.000000   \n",
       "\n",
       "     JinsEyeMovement Dim-4 (var)  JinsEyeMovement Dim-4 (max)  \\\n",
       "0                       0.009803                          1.0   \n",
       "1                       0.000000                          0.0   \n",
       "2                       0.000000                          0.0   \n",
       "3                       0.009900                          1.0   \n",
       "4                       0.000000                          0.0   \n",
       "..                           ...                          ...   \n",
       "254                     0.000000                          0.0   \n",
       "255                     0.000000                          0.0   \n",
       "256                     0.009900                          1.0   \n",
       "257                     0.000000                          0.0   \n",
       "258                     0.000000                          0.0   \n",
       "\n",
       "     JinsEyeMovement Dim-4 (min)  rightHand  label  \n",
       "0                            0.0          0      0  \n",
       "1                            0.0          0      0  \n",
       "2                            0.0          0      0  \n",
       "3                            0.0          0      0  \n",
       "4                            0.0          0      0  \n",
       "..                           ...        ...    ...  \n",
       "254                          0.0          0      5  \n",
       "255                          0.0          0      5  \n",
       "256                          0.0          0      5  \n",
       "257                          0.0          0      5  \n",
       "258                          0.0          0      5  \n",
       "\n",
       "[259 rows x 126 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Performing a principal Component analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df.iloc[:, :-1].to_numpy() # All features except label\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "pca = PCA(n_components=10) # CAVE: maybe change the amount of principal components to use\r\n",
    "\r\n",
    "# Standardizing the features\r\n",
    "X = StandardScaler().fit_transform(X)\r\n",
    "\r\n",
    "principal_components = pca.fit_transform(X)\r\n",
    "\r\n",
    "principal_df = pd.DataFrame(data=principal_components)\r\n",
    "\r\n",
    "print(pca.explained_variance_ratio_)\r\n",
    "print(pca.get_params)\r\n",
    "principal_df\r\n",
    "# Plot PCA?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature selections with RandomForestClassifier and SelectFromModel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df.iloc[:, :-1]\r\n",
    "y = df[\"label\"]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\r\n",
    "\r\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100, random_state=42))\r\n",
    "sel.fit(X_train, y_train)\r\n",
    "\r\n",
    "sel.get_support()\r\n",
    "\r\n",
    "# Array of columns, that regarded as best features by random forest classifier above\r\n",
    "selected_feats = X_train.columns[(sel.get_support())]\r\n",
    "\r\n",
    "selected_feats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RandomForestClassifier without pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# X = principal_components # All features except label\r\n",
    "X = df.iloc[:, :-1].to_numpy() # All features except label\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    "\r\n",
    "clf = RandomForestClassifier(random_state=0)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "predicted = clf.predict(X_test)\r\n",
    "\r\n",
    "# Cross fold validation - 10 folds\r\n",
    "scores = cross_val_score(clf, X, y, cv=10)\r\n",
    "\r\n",
    "# Scores value\r\n",
    "print (f\"Score: {clf.score(X_test, y_test)}\")\r\n",
    "print(f\"cross fold validation scores: {scores}\")\r\n",
    "print(f\"cross fold validation score average: {scores.mean()}\")\r\n",
    "print(f\"cross fold validation score standard deviation: {scores.std()}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RandomForestClassifier with selected features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[selected_feats].to_numpy()\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    "\r\n",
    "clf = RandomForestClassifier(random_state=0)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Cross fold validation - 10 folds\r\n",
    "scores = cross_val_score(clf, X, y, cv=10)\r\n",
    "\r\n",
    "# Scores value\r\n",
    "print (f\"Score: {clf.score(X_test, y_test)}\")\r\n",
    "print(f\"cross fold validation scores: {scores}\")\r\n",
    "print(f\"cross fold validation score average: {scores.mean()}\")\r\n",
    "print(f\"cross fold validation score standard deviation: {scores.std()}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression with StandardScaler and selected features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[selected_feats].to_numpy()\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "# Standardizing the features\r\n",
    "X = StandardScaler().fit_transform(X)\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\r\n",
    "\r\n",
    "clf = LogisticRegression(random_state=0, solver=\"saga\", max_iter=1000).fit(X_train, y_train)\r\n",
    "\r\n",
    "scores = cross_val_score(clf, X, y, cv=10)\r\n",
    "\r\n",
    "# Scores value\r\n",
    "print(f\"Score: {clf.score(X_test, y_test)}\")\r\n",
    "print(f\"cross fold validation scores: {scores}\")\r\n",
    "print(f\"cross fold validation score average: {scores.mean()}\")\r\n",
    "print(f\"cross fold validation score standard deviation: {scores.std()}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM with StandardScaler and selected features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[selected_feats].to_numpy()\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "# Standardizing the features\r\n",
    "X = StandardScaler().fit_transform(X)\r\n",
    "\r\n",
    "clf = SVC(gamma='auto', random_state=0).fit(X_train, y_train)\r\n",
    "\r\n",
    "scores = cross_val_score(clf, X, y, cv=10)\r\n",
    "\r\n",
    "# Scores value\r\n",
    "print(f\"Score: {clf.score(X_test, y_test)}\")\r\n",
    "print(f\"cross fold validation scores: {scores}\")\r\n",
    "print(f\"cross fold validation score average: {scores.mean()}\")\r\n",
    "print(f\"cross fold validation score standard deviation: {scores.std()}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN with StandardScaler and selected features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[selected_feats].to_numpy()\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "clf = KNeighborsClassifier(n_neighbors=2)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "scores = cross_val_score(clf, X, y, cv=10)\r\n",
    "\r\n",
    "# Scores value\r\n",
    "print(f\"Score: {clf.score(X_test, y_test)}\")\r\n",
    "print(f\"cross fold validation scores: {scores}\")\r\n",
    "print(f\"cross fold validation score average: {scores.mean()}\")\r\n",
    "print(f\"cross fold validation score standard deviation: {scores.std()}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes without standardization necessary with selected features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df.iloc[:, :-1].to_numpy() # All features except label\r\n",
    "# X = df.iloc[selected_feats].to_numpy()\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
    "\r\n",
    "scaler = MinMaxScaler()\r\n",
    "\r\n",
    "X_train = scaler.fit_transform(X_train)\r\n",
    "X_test = scaler.fit_transform(X_test)\r\n",
    "\r\n",
    "clf = MultinomialNB()\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "print(f\"Score: {clf.score(X_test, y_test)}\")\r\n",
    "print(f\"cross fold validation scores: {scores}\")\r\n",
    "print(f\"cross fold validation score average: {scores.mean()}\")\r\n",
    "print(f\"cross fold validation score standard deviation: {scores.std()}\")\r\n",
    "\r\n",
    "proba = clf.predict_proba(X_train)\r\n",
    "\r\n",
    "np.set_printoptions(suppress=True)\r\n",
    "print(f\"Probabilites per dataset: {proba}\")\r\n",
    "\r\n",
    "df_proba = pd.DataFrame(proba, columns=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\", \"Class 4\", \"Class 5\"])\r\n",
    "pd.set_option(\"display.float_format\", lambda x: '%.5f' % x)\r\n",
    "df_proba"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AUC-ROC Curve (OneVsRest SVM)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[selected_feats].to_numpy()\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "# Standardizing the features\r\n",
    "X = StandardScaler().fit_transform(X)\r\n",
    "\r\n",
    "# Binarize the output\r\n",
    "y = label_binarize(y, classes=[0, 1, 2, 3, 4, 5])\r\n",
    "n_classes = y.shape[1]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "clf = OneVsRestClassifier(SVC(random_state=42)).fit(X_train, y_train)\r\n",
    "\r\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)\r\n",
    "\r\n",
    "# Compute ROC curve and ROC area for each class\r\n",
    "fpr = dict()\r\n",
    "tpr = dict()\r\n",
    "roc_auc = dict()\r\n",
    "for i in range(n_classes):\r\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\r\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\r\n",
    "\r\n",
    "# Compute micro-average ROC curve and ROC area\r\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\r\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\r\n",
    "\r\n",
    "# First aggregate all false positive rates\r\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\r\n",
    "\r\n",
    "# Then interpolate all ROC curves at this points\r\n",
    "mean_tpr = np.zeros_like(all_fpr)\r\n",
    "for i in range(n_classes):\r\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\r\n",
    "\r\n",
    "# Finally average it and compute AUC\r\n",
    "mean_tpr /= n_classes\r\n",
    "\r\n",
    "fpr[\"macro\"] = all_fpr\r\n",
    "tpr[\"macro\"] = mean_tpr\r\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\r\n",
    "\r\n",
    "lw = 2\r\n",
    "\r\n",
    "# Plot all ROC curves\r\n",
    "plt.figure()\r\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\r\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\r\n",
    "               ''.format(roc_auc[\"micro\"]),\r\n",
    "         color='deeppink', linestyle=':', linewidth=4)\r\n",
    "\r\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\r\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\r\n",
    "               ''.format(roc_auc[\"macro\"]),\r\n",
    "         color='navy', linestyle=':', linewidth=4)\r\n",
    "\r\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blueviolet', 'saddlebrown', 'crimson'])\r\n",
    "for i, color in zip(range(n_classes), colors):\r\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\r\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\r\n",
    "             ''.format(i, roc_auc[i]))\r\n",
    "\r\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\r\n",
    "plt.xlim([0.0, 1.0])\r\n",
    "plt.ylim([0.0, 1.05])\r\n",
    "plt.xlabel('False Positive Rate')\r\n",
    "plt.ylabel('True Positive Rate')\r\n",
    "plt.title('AUC-ROC Curve (SVM)')\r\n",
    "plt.legend(loc=\"lower right\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AUC-ROC Curve (OneVsRest Logistic Regression)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[selected_feats].to_numpy()\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "# Standardizing the features\r\n",
    "X = StandardScaler().fit_transform(X)\r\n",
    "\r\n",
    "# Binarize the output\r\n",
    "y = label_binarize(y, classes=[0, 1, 2, 3, 4, 5])\r\n",
    "n_classes = y.shape[1]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "clf = OneVsRestClassifier(LogisticRegression(random_state=0,solver='lbfgs', max_iter=1000)).fit(X_train, y_train)\r\n",
    "\r\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)\r\n",
    "\r\n",
    "# Compute ROC curve and ROC area for each class\r\n",
    "fpr = dict()\r\n",
    "tpr = dict()\r\n",
    "roc_auc = dict()\r\n",
    "for i in range(n_classes):\r\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\r\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\r\n",
    "\r\n",
    "# Compute micro-average ROC curve and ROC area\r\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\r\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\r\n",
    "\r\n",
    "# First aggregate all false positive rates\r\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\r\n",
    "\r\n",
    "# Then interpolate all ROC curves at this points\r\n",
    "mean_tpr = np.zeros_like(all_fpr)\r\n",
    "for i in range(n_classes):\r\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\r\n",
    "\r\n",
    "# Finally average it and compute AUC\r\n",
    "mean_tpr /= n_classes\r\n",
    "\r\n",
    "fpr[\"macro\"] = all_fpr\r\n",
    "tpr[\"macro\"] = mean_tpr\r\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\r\n",
    "\r\n",
    "lw = 2\r\n",
    "\r\n",
    "# Plot all ROC curves\r\n",
    "plt.figure()\r\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\r\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\r\n",
    "               ''.format(roc_auc[\"micro\"]),\r\n",
    "         color='deeppink', linestyle=':', linewidth=4)\r\n",
    "\r\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\r\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\r\n",
    "               ''.format(roc_auc[\"macro\"]),\r\n",
    "         color='navy', linestyle=':', linewidth=4)\r\n",
    "\r\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blueviolet', 'saddlebrown', 'crimson'])\r\n",
    "for i, color in zip(range(n_classes), colors):\r\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\r\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\r\n",
    "             ''.format(i, roc_auc[i]))\r\n",
    "\r\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\r\n",
    "plt.xlim([0.0, 1.0])\r\n",
    "plt.ylim([0.0, 1.05])\r\n",
    "plt.xlabel('False Positive Rate')\r\n",
    "plt.ylabel('True Positive Rate')\r\n",
    "plt.title('AUC-ROC Curve (Logistic Regression)')\r\n",
    "plt.legend(loc=\"lower right\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AUC-ROC Curve (OneVsRest RandomForest)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = df[selected_feats].to_numpy()\r\n",
    "y = df['label'].to_numpy()\r\n",
    "\r\n",
    "# Standardizing the features\r\n",
    "X = StandardScaler().fit_transform(X)\r\n",
    "\r\n",
    "# Binarize the output\r\n",
    "y = label_binarize(y, classes=[0, 1, 2, 3, 4, 5])\r\n",
    "n_classes = y.shape[1]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "clf = OneVsRestClassifier(RandomForestClassifier(random_state=0)).fit(X_train, y_train)\r\n",
    "\r\n",
    "y_score = clf.fit(X_train, y_train).predict_proba(X_test)\r\n",
    "\r\n",
    "# Compute ROC curve and ROC area for each class\r\n",
    "fpr = dict()\r\n",
    "tpr = dict()\r\n",
    "roc_auc = dict()\r\n",
    "for i in range(n_classes):\r\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\r\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\r\n",
    "\r\n",
    "# Compute micro-average ROC curve and ROC area\r\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\r\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\r\n",
    "\r\n",
    "# First aggregate all false positive rates\r\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\r\n",
    "\r\n",
    "# Then interpolate all ROC curves at this points\r\n",
    "mean_tpr = np.zeros_like(all_fpr)\r\n",
    "for i in range(n_classes):\r\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\r\n",
    "\r\n",
    "# Finally average it and compute AUC\r\n",
    "mean_tpr /= n_classes\r\n",
    "\r\n",
    "fpr[\"macro\"] = all_fpr\r\n",
    "tpr[\"macro\"] = mean_tpr\r\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\r\n",
    "\r\n",
    "lw = 2\r\n",
    "\r\n",
    "# Plot all ROC curves\r\n",
    "plt.figure()\r\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\r\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\r\n",
    "               ''.format(roc_auc[\"micro\"]),\r\n",
    "         color='deeppink', linestyle=':', linewidth=4)\r\n",
    "\r\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\r\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\r\n",
    "               ''.format(roc_auc[\"macro\"]),\r\n",
    "         color='navy', linestyle=':', linewidth=4)\r\n",
    "\r\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blueviolet', 'saddlebrown', 'crimson'])\r\n",
    "for i, color in zip(range(n_classes), colors):\r\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\r\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\r\n",
    "             ''.format(i, roc_auc[i]))\r\n",
    "\r\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\r\n",
    "plt.xlim([0.0, 1.0])\r\n",
    "plt.ylim([0.0, 1.05])\r\n",
    "plt.xlabel('False Positive Rate')\r\n",
    "plt.ylabel('True Positive Rate')\r\n",
    "plt.title('AUC-ROC Curve (Random Forest)')\r\n",
    "plt.legend(loc=\"lower right\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from helper import compare_classifier_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print('Without standardization and with no feature selection')\r\n",
    "\r\n",
    "compare_classifier_score(df, standardization=False, featureSelection='none')\r\n",
    "\r\n",
    "print('Without standardization and with random forest feature selection')\r\n",
    "\r\n",
    "compare_classifier_score(df, standardization=False, featureSelection='randomForest')\r\n",
    "\r\n",
    "print('Without standardization and with pca feature selection')\r\n",
    "\r\n",
    "compare_classifier_score(df, standardization=False, featureSelection='pca')\r\n",
    "\r\n",
    "print('With standardization and with no feature selection')\r\n",
    "\r\n",
    "compare_classifier_score(df, standardization=True, featureSelection='none')\r\n",
    "\r\n",
    "print('With standardization and with random forest feature selection')\r\n",
    "\r\n",
    "compare_classifier_score(df, standardization=True, featureSelection='randomForest')\r\n",
    "\r\n",
    "print('With standardization and with pca feature selection')\r\n",
    "\r\n",
    "compare_classifier_score(df, standardization=True, featureSelection='pca')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Without standardization and with no feature selection\n",
      "cross fold validation score average for Random Forest: 0.9692307692307693\n",
      "cross fold validation score average for Logistic Regression: 0.7841538461538462\n",
      "cross fold validation score average for SVM: 0.22430769230769232\n",
      "cross fold validation score average for Nearest Neighbors: 0.6066153846153847\n",
      "cross fold validation score average for Naive Bayes: 0.7766153846153846\n",
      "Without standardization and with random forest feature selection\n",
      "cross fold validation score average for Random Forest: 0.9692307692307693\n",
      "cross fold validation score average for Logistic Regression: 0.9343076923076923\n",
      "cross fold validation score average for SVM: 0.45199999999999996\n",
      "cross fold validation score average for Nearest Neighbors: 0.8807692307692306\n",
      "cross fold validation score average for Naive Bayes: 0.8266153846153846\n",
      "Without standardization and with pca feature selection\n",
      "cross fold validation score average for Random Forest: 0.7415384615384615\n",
      "cross fold validation score average for Logistic Regression: 0.7529230769230769\n",
      "cross fold validation score average for SVM: 0.1970769230769231\n",
      "cross fold validation score average for Nearest Neighbors: 0.5104615384615385\n",
      "cross fold validation score average for Naive Bayes: 0.46399999999999997\n",
      "With standardization and with no feature selection\n",
      "cross fold validation score average for Random Forest: 0.9692307692307693\n",
      "cross fold validation score average for Logistic Regression: 0.9267692307692308\n",
      "cross fold validation score average for SVM: 0.9575384615384614\n",
      "cross fold validation score average for Nearest Neighbors: 0.9153846153846154\n",
      "cross fold validation score average for Naive Bayes: 0.7766153846153846\n",
      "With standardization and with random forest feature selection\n",
      "cross fold validation score average for Random Forest: 0.9730769230769232\n",
      "cross fold validation score average for Logistic Regression: 0.9536923076923077\n",
      "cross fold validation score average for SVM: 0.9615384615384615\n",
      "cross fold validation score average for Nearest Neighbors: 0.9576923076923076\n",
      "cross fold validation score average for Naive Bayes: 0.8266153846153846\n",
      "With standardization and with pca feature selection\n",
      "cross fold validation score average for Random Forest: 0.7415384615384615\n",
      "cross fold validation score average for Logistic Regression: 0.7530769230769231\n",
      "cross fold validation score average for SVM: 0.7416923076923077\n",
      "cross fold validation score average for Nearest Neighbors: 0.7032307692307693\n",
      "cross fold validation score average for Naive Bayes: 0.46399999999999997\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('myenv': conda)"
  },
  "interpreter": {
   "hash": "8be6fd978d3d2b147fc52b9ee003cbc0a855db38208b8ec99a030e59408ace64"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}